{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Example curve prediction script\n",
    "In this notebook we will try to predict the function coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from prettytable import PrettyTable\n",
    "%matplotlib widget\n",
    "\n",
    "from generate_TF import GenerateTF\n",
    "\n",
    "# from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def scale(X):\n",
    "    return (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "def descale(X, X_old):\n",
    "    return (X_old.max(axis=0) - X_old.min(axis=0)) * X + X_old.min(axis=0)\n",
    "\n",
    "# plot train and validation loss\n",
    "%matplotlib widget\n",
    "\n",
    "def plot_loss(loss, val_loss, epoch=(-1, -1)):\n",
    "    fig = plt.figure()\n",
    "\n",
    "    if epoch[0] == -1:\n",
    "        start_idx = 0\n",
    "    else:\n",
    "        start_idx = epoch[0]\n",
    "\n",
    "    if epoch[1] == -1:\n",
    "        end_idx = len(loss)\n",
    "    else:\n",
    "        end_idx = epoch[1]\n",
    "    loss = loss[start_idx: end_idx]\n",
    "    val_loss = val_loss[start_idx: end_idx]\n",
    "    plt.plot(np.arange(start_idx, end_idx), loss, label='train')\n",
    "    plt.plot(np.arange(start_idx, end_idx), val_loss, label='validation')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel(criterion_name)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_pickle('./data/transfer-functions-82000.pkl')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "for index, row in df.sample(n=3).iterrows():\n",
    "    y = row['y']\n",
    "    x = row['x']\n",
    "    plt.plot(x, y)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Extract the target variables\n",
    "param_a = df.pop('phi')\n",
    "param_b = df.pop('g_oo')\n",
    "\n",
    "# All x should be equal\n",
    "x = df.iloc[0].x.astype(np.float32)\n",
    "df.drop(columns='x', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# target is the target vector\n",
    "target = np.array((param_a, param_b), dtype=np.float32).T\n",
    "\n",
    "# scaled_target = scale(target)\n",
    "target_scaler = preprocessing.StandardScaler().fit(target)\n",
    "# print(target_scaler.mean_)\n",
    "# print(target_scaler.scale_)\n",
    "scaled_target = target_scaler.transform(target)\n",
    "# target = torch.tensor(target, dtype=torch.float32)\n",
    "print(target[5:15])\n",
    "# scaler_target = preprocessing.MinMaxScaler()\n",
    "scaled_target = torch.tensor(scaled_target)\n",
    "print(scaled_target[5:15])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Only the input points have been left\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "values = np.zeros((len(df), len(df.iloc[0,0])), dtype=np.float32)\n",
    "# print(values.shape)\n",
    "index = 0\n",
    "for _, row in df.iterrows():\n",
    "    values[index, :] = row.values[0]\n",
    "    index += 1\n",
    "print(values.shape)\n",
    "print(type(values))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert data to torch tensor\n",
    "data_scaler = preprocessing.StandardScaler().fit(values)\n",
    "# scaled_values = scale(values)\n",
    "scaled_values = data_scaler.transform(values)\n",
    "# scaled_values = values\n",
    "# print(data_scaler.mean_)\n",
    "# print(data_scaler.scale_)\n",
    "data = torch.tensor(scaled_values)\n",
    "# data = torch.tensor(values, dtype=torch.float32)\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, scaled_target, test_size=0.2, random_state=2)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the network architecture2\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, name='model', activation_func=F.gelu,\n",
    "                 hidden_1=140, hidden_2=110, hidden_3=0,\n",
    "                 kernel_size=10, stride=10, trim_edges=120):\n",
    "        super(Net, self).__init__()\n",
    "        self.activate = activation_func\n",
    "        self.name = name\n",
    "        # A layer that trims out the edges\n",
    "        self.center = nn.ConstantPad1d(-trim_edges, 0)\n",
    "        n_inputs -= 2 * trim_edges\n",
    "        # An avgpooling layer to smoothen the curve\n",
    "        padding = 0\n",
    "        n_pool_out = (n_inputs + 2 * padding - kernel_size)//stride +1\n",
    "        self.pool1 = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "        # linear layer (n_pool_out -> hidden_1)\n",
    "        self.fc1 = nn.Linear(n_pool_out, hidden_1)\n",
    "\n",
    "        # linear layer (n_hidden -> hidden_2)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "\n",
    "        # linear layer (n_hidden -> n_outputs)\n",
    "        if hidden_3 > 0:\n",
    "            self.fc3 = nn.Linear(hidden_2, hidden_3)\n",
    "            self.fc4 = nn.Linear(hidden_3, n_outputs)\n",
    "        else:\n",
    "            self.fc3 = nn.Linear(hidden_2, n_outputs)\n",
    "            self.fc4 = None\n",
    "\n",
    "        # dropout layer (p=0.2)\n",
    "        # dropout prevents overfitting of data\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # remove some points from the edges\n",
    "        x = self.center(x)\n",
    "\n",
    "        # This performs the average pooling layer\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = self.activate(self.fc1(x))\n",
    "\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = self.activate(self.fc2(x))\n",
    "\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        if self.fc4:\n",
    "            x = self.dropout(self.activate(self.fc3(x)))\n",
    "            # add outputlayer\n",
    "            x = self.fc4(x)\n",
    "        else:\n",
    "            # add output layer\n",
    "            x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def get_accuracy(self, pred_arr, original_arr, pct=0.1):\n",
    "        n_correct = torch.sum((torch.abs(pred_arr-original_arr) < torch.abs(pct * original_arr)))\n",
    "        acc = (n_correct.item() * 100.0 / len(original_arr))\n",
    "        return acc\n",
    "\n",
    "\n",
    "    def save(self, name='model.pt'):\n",
    "        torch.save(self.state_dict(), name)\n",
    "\n",
    "\n",
    "    def train_net(self, optimizer, criterion, X_train, y_train, X_test, y_test, num_epochs=100):\n",
    "        l_train_loss=[]\n",
    "        l_train_accuracy=[]\n",
    "        l_test_loss=[]\n",
    "        l_test_accuracy=[]\n",
    "        min_test_loss = np.Inf\n",
    "        for epoch in range(num_epochs):\n",
    "            # put the model in training mode\n",
    "            self.train()\n",
    "\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output_train = self(X_train)\n",
    "\n",
    "            # l_train_accuracy.append(self.get_accuracy(output_train, y_train))\n",
    "\n",
    "            #calculate the loss\n",
    "            train_loss = criterion(output_train, y_train)\n",
    "            l_train_loss.append(train_loss.item())\n",
    "\n",
    "            #backward pass: compute gradient of the loss with respect to model parameters\n",
    "            train_loss.backward()\n",
    "\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output_test = self(X_test)\n",
    "                test_loss = criterion(output_test, y_test)\n",
    "                l_test_loss.append(test_loss.item())\n",
    "                # l_test_accuracy.append(self.get_accuracy(output_test, y_test))\n",
    "\n",
    "            if l_test_loss[-1] < min_test_loss:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}: Test loss decreased ({min_test_loss:.6f} --> {l_test_loss[-1]:.6f}), saving model.\")\n",
    "                self.save(f'models/{self.name}.pt')\n",
    "                min_test_loss = l_test_loss[-1]\n",
    "\n",
    "            if (epoch + 1) % 50 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {l_train_loss[-1]:.4f}, Test Loss: {l_test_loss[-1]:.4f}\")\n",
    "\n",
    "        return l_train_loss, l_train_accuracy, l_test_loss, l_test_accuracy\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize model, loss function and optimizer\n",
    "\n",
    "n_inputs = data.shape[1]\n",
    "# we will build one model per output target\n",
    "n_outputs = 1\n",
    "model1 = Net(n_inputs, n_outputs, name='model1', activation_func=F.gelu,\n",
    "                hidden_1=140, hidden_2=140, hidden_3=0,\n",
    "                kernel_size=5, stride=5, trim_edges=100)\n",
    "print(model1)\n",
    "\n",
    "# specify loss function (regression)\n",
    "criterion = nn.MSELoss(); criterion_name = 'MSE'\n",
    "# criterion = nn.L1Loss(); criterion_name = 'MAE'\n",
    "\n",
    "# specify optimizer\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.01)\n",
    "\n",
    "# train the network\n",
    "train_loss1, train_accuracy1, test_loss1, test_accuracy1 = model1.train_net(\n",
    "    optimizer1, criterion, X_train, y_train[:, 0].view(-1,1), X_test, y_test[:, 0].view(-1,1), 500)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(train_loss1, test_loss1, epoch=(50,-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize model, loss function and optimizer\n",
    "n_inputs = data.shape[1]\n",
    "# we will build one model per output target\n",
    "n_outputs = 1\n",
    "\n",
    "model2 = Net(n_inputs, n_outputs, name='model2', activation_func=F.gelu,\n",
    "                hidden_1=140, hidden_2=110, hidden_3=0,\n",
    "                kernel_size=10, stride=10, trim_edges=120)\n",
    "print(model2)\n",
    "\n",
    "# specify loss function (regression)\n",
    "criterion = nn.MSELoss(); criterion_name = 'MSE'\n",
    "# criterion = nn.L1Loss(); criterion_name = 'MAE'\n",
    "\n",
    "# specify optimizer\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=0.01)\n",
    "\n",
    "# train the network\n",
    "\n",
    "train_loss2, train_accuracy2, test_loss2, test_accuracy2 = model2.train_net(\n",
    "    optimizer2, criterion, X_train, y_train[:, 1].view(-1,1), X_test, y_test[:, 1].view(-1,1), 500)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(train_loss2, test_loss2, epoch=(50, -1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Hyper parameter tuning\n",
    "# criterion = nn.L1Loss(); criterion_name = 'MAE'\n",
    "n_inputs = data.shape[1]\n",
    "n_outputs = 1\n",
    "test_results = []\n",
    "num_epochs = 200\n",
    "# for activ_f, activ_f_name in [(F.relu, 'relu'), (F.relu6, 'relu6'), (F.gelu, 'gelu')]:\n",
    "for activ_f, activ_f_name in [(F.gelu, 'gelu')]:\n",
    "    for kernel_size, stride in [(5, 5)]:\n",
    "        for hidden_1 in [140]:\n",
    "            for hidden_2 in [140]:\n",
    "                for hidden_3 in [0]:\n",
    "                    for trim_edges in [100]:\n",
    "                        print(f\"Training net with: activation, kernel_size, stride, h_1, h_2, h_3, trim \"\n",
    "                              f\"= ({activ_f_name}, {kernel_size}, {stride},\"\n",
    "                              f\"{hidden_1}, {hidden_2}, {hidden_3}, {trim_edges})\")\n",
    "                        model = Net(n_inputs, n_outputs, name='model1', activation_func=activ_f,\n",
    "                                    hidden_1=hidden_1, hidden_2=hidden_2, hidden_3=hidden_3,\n",
    "                                    kernel_size=kernel_size, stride=stride, trim_edges=trim_edges)\n",
    "                        criterion = nn.MSELoss(); criterion_name = 'MSE'\n",
    "                        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "                        train_loss, train_accuracy, test_loss, test_accuracy = model.train_net(\n",
    "                            optimizer, criterion, X_train, y_train[:, 0].view(-1,1), X_test, y_test[:, 0].view(-1,1), num_epochs)\n",
    "                        test_results.append([activ_f_name, kernel_size, stride, hidden_1, hidden_2, hidden_3,\n",
    "                                             trim_edges, np.min(test_loss)])\n",
    "        # plot_loss(train_loss, test_loss, epoch=(10,-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "table = PrettyTable()\n",
    "table.field_names = [\"activation\", \"kernel size\", \"stride\",\n",
    "                     \"hidden_1\", \"hidden_2\", \"hidden_3\", \"trim_edges\", \"Min Loss\"]\n",
    "test_results.sort(key=lambda x: x[-1])\n",
    "for row in test_results:\n",
    "    table.add_row(row)\n",
    "# print('kernel_size, stride, Min loss')\n",
    "print(table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load model with the highest accuracy\n",
    "model1.load_state_dict(torch.load('models/model1.pt'))\n",
    "model2.load_state_dict(torch.load('models/model2.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make predictions\n",
    "random_idx = np.random.choice(np.arange(len(X_test)), size=100, replace=False)\n",
    "X_validate = X_test[random_idx]\n",
    "y_validate = y_test[random_idx]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    yhat1 = model1(X_validate)\n",
    "    yhat2 = model2(X_validate)\n",
    "# yhat = torch.tensor([yhat1, yhat2])\n",
    "X_validate_new = data_scaler.inverse_transform(X_validate.numpy())\n",
    "yhat = (np.array([yhat1.numpy(), yhat2.numpy()]).T).reshape(-1, 2)\n",
    "yhat_new = target_scaler.inverse_transform(yhat)\n",
    "y_validate_new = target_scaler.inverse_transform(y_validate.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the validation curves\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "gen_tf = GenerateTF(fb_attn_index=3, with_noise=False)\n",
    "x = gen_tf.frequency.astype(np.float32)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"idx\", \"param\", \"original\", \"model\", \"opt\"] #, \"model+opt\"]\n",
    "# print(table)\n",
    "\n",
    "for idx in np.random.choice(np.arange(0, len(X_validate_new)), size=3):\n",
    "    try:\n",
    "        popt, _  = curve_fit(gen_tf, x, X_validate_new[idx], bounds=([-20, 1e-4], [20, 1e-2]), method='trf')\n",
    "        # Initial guesses coming from the model\n",
    "        # poptModel,_ = curve_fit(gen_tf, x, X_validate_new[idx], bounds=([-20, 1e-4], [20, 1e-2]), method='trf', p0=yhat_new[idx])\n",
    "    except:\n",
    "        print(f'Scipy curve fit failed for idx: {idx}')\n",
    "        continue\n",
    "\n",
    "    # print('Param, Original, Model, Optimizer')\n",
    "    table.add_row([idx, 'phi', y_validate_new[idx][0], yhat_new[idx][0], popt[0]]) #, poptModel[0]])\n",
    "    table.add_row([idx, 'g_oo', y_validate_new[idx][1], yhat_new[idx][1], popt[1]]) #, poptModel[1]])\n",
    "\n",
    "    # print('phi', y_validate_new[idx][0], yhat_new[idx][0], popt[0])\n",
    "    # print('g_oo', y_validate_new[idx][1], yhat_new[idx][1], popt[1])\n",
    "\n",
    "    p = plt.plot(x, gen_tf(x, *(y_validate_new[idx])), label=f'real_{idx}', ls='-')\n",
    "    plt.plot(x, gen_tf(x, *(yhat_new[idx])), label=f'model_{idx}', ls='--', color=p[0].get_color())\n",
    "    plt.plot(x, gen_tf(x, *popt), label=f'opt_{idx}', ls=':', color=p[0].get_color())\n",
    "    # plt.plot(x, gen_tf(x, *poptModel), label=f'opt+model_{idx}', ls='-.', color=p[0].get_color())\n",
    "print(table)\n",
    "plt.legend(ncol=3)\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calc_mae_model(yhat, yreal):\n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     yhat = model(test_x)\n",
    "    # new_yhat = descale(yhat.numpy(), target)\n",
    "    # new_y = descale(test_y.numpy(), target)\n",
    "    #\n",
    "    # new_yhat = yhat.numpy()\n",
    "    # new_y = test_y.numpy()\n",
    "\n",
    "    return np.abs(np.mean(np.abs(yhat-yreal), axis=0)/ np.max(yreal, axis=0))\n",
    "\n",
    "def calc_mae_optimize(test_x, test_y):\n",
    "    gen_tf = GenerateTF(fb_attn_index=3, with_noise=False)\n",
    "    x = gen_tf.frequency.astype(np.float32)\n",
    "    coeffs = []\n",
    "    real = []\n",
    "    for xi, yi in zip(test_x, test_y):\n",
    "        try:\n",
    "            popt, pcov  = curve_fit(gen_tf, x, xi, bounds=([-20, 1e-4], [20, 1e-2]), method='trf')\n",
    "        except:\n",
    "            # print(f'Scipy curve fit failed for idx: {idx}')\n",
    "            continue\n",
    "        coeffs.append(popt)\n",
    "        real.append(yi)\n",
    "    yhat = np.array(coeffs)\n",
    "    real = np.array(real)\n",
    "    return np.abs(np.mean(np.abs(yhat - real), axis=0)/ np.max(real, axis=0))\n",
    "\n",
    "# def calc_mae_optimize_model(ymodel, test_x, test_y):\n",
    "#     gen_tf = GenerateTF(fb_attn_index=3, with_noise=False)\n",
    "#     x = gen_tf.frequency.astype(np.float32)\n",
    "#     coeffs = []\n",
    "#     real = []\n",
    "#     for xi, yi, yhi in zip(test_x, test_y, ymodel):\n",
    "#         try:\n",
    "#             popt, pcov  = curve_fit(gen_tf, x, xi, bounds=([-20, 1e-4], [20, 1e-2]), method='trf', p0=yhi)\n",
    "#         except:\n",
    "#             # print(f'Scipy curve fit failed for idx: {idx}')\n",
    "#             continue\n",
    "#         coeffs.append(popt)\n",
    "#         real.append(yi)\n",
    "#     yhat = np.array(coeffs)\n",
    "#     real = np.array(real)\n",
    "#     return np.abs(np.mean(np.abs(yhat - real), axis=0)/ np.max(real, axis=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mae_model = calc_mae_model(yhat_new, y_validate_new)\n",
    "mae_optimize = calc_mae_optimize(X_validate_new, y_validate_new)\n",
    "# mae_optimize_model = calc_mae_optimize_model(yhat_new, X_validate_new, y_validate_new)\n",
    "print('Model mae: ', mae_model)\n",
    "print('Optimize mae: ', mae_optimize)\n",
    "# print('Optimize+Model mae: ', mae_optimize_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}