{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Example curve prediction script\n",
    "In this notebook we will try to predict the function coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from generate_TF import GenerateTF, get_freq\n",
    "from scipy.optimize import curve_fit\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from pytorchClassifiers import get_keras_nn, plot_history\n",
    "\n",
    "avg_pool1d = keras.layers.AveragePooling1D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_pickle('./data/tf-ampl-response-82000-noise0.1.pkl')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the target variables\n",
    "phase = df.pop('phase')\n",
    "gain = df.pop('gain')\n",
    "\n",
    "# All fmax, np should be equal\n",
    "fmax = df.iloc[0].fmax\n",
    "NP = df.iloc[0].np\n",
    "df.drop(columns=['fmax', 'np'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# target_orig is the vector with the originale phase, gain labels\n",
    "target_orig = np.array((phase, gain), dtype=np.float32).T\n",
    "\n",
    "target_scaler = preprocessing.StandardScaler().fit(target_orig)\n",
    "# target is scaled, better for training\n",
    "target = target_scaler.transform(target_orig)\n",
    "# target = tf.convert_to_tensor(target, dtype=tf.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# our dataset is 3D\n",
    "values = np.zeros((len(df), len(df.iloc[0].real), 3), dtype=np.float32)\n",
    "print(values.shape)\n",
    "for index, row in df.iterrows():\n",
    "    # print(row)\n",
    "    values[index, :, 0] = row.real\n",
    "    values[index, :, 1] = row.imag\n",
    "    values[index, :, 2] = row.amplitude\n",
    "data = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split in train and test\n",
    "X_train_orig, X_test_orig, y_train, y_test, y_train_orig, y_test_orig = train_test_split(\n",
    "    data, target, target_orig, test_size=0.2, random_state=0)\n",
    "\n",
    "# further divide X_test in test + validate\n",
    "X_test_orig, X_validate_orig, y_test, y_validate, y_test_orig, y_validate_orig = \\\n",
    "    train_test_split(X_test_orig, y_test, y_test_orig, test_size=0.4, random_state=1)\n",
    "\n",
    "X_train = X_train_orig[:, :, :2]\n",
    "X_test = X_test_orig[:, :, :2]\n",
    "X_validate = X_validate_orig[:, :, :2]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validate.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_validate.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_model_builder(hp):\n",
    "    # n_inputs, n_outputs, name='phase_regressor', activation='relu',\n",
    "    #              layers=[140, 110], kernel_size=5, stride=5, trim_edges=120,\n",
    "    #              dropout=0.0, with_norm=False):\n",
    "    # initialize model\n",
    "    n_inputs = X_train.shape[1:]\n",
    "    n_outputs = 1\n",
    "    name = 'keras_phase_reg'\n",
    "    # Define HyperParameter Space\n",
    "    activation = hp.Choise('activate', values=['relu', 'gelu'])\n",
    "    with_norm = hp.Boolean('norm')\n",
    "    kernel_size = hp.Int('pool', min_value=3, max_value=10, step=1)\n",
    "    stride = kernel_size\n",
    "    trim_edges = hp.Int('crop', min_value=100, max_value=160, step=5)\n",
    "    dropout = hp.Fixed('dropout', value=0.2)\n",
    "    layer1 = hp.Fixed('fc1', min_value=400, max_value=600, step=20)\n",
    "    layer2 = hp.Fixed('fc2', min_value=100, max_value=300, step=20)\n",
    "    layers = [layer1, layer2]\n",
    "\n",
    "    lr = hp.Choice('learning_rate', values=[0.001, 0.005, 0.01])\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    # Model architecture\n",
    "    model = keras.models.Sequential(name=name)\n",
    "    # just set input shape\n",
    "    model.add(keras.Input(shape=n_inputs))\n",
    "    # crop the edges\n",
    "    model.add(keras.layers.Cropping1D(cropping=trim_edges, name='Crop'))\n",
    "    # smoothing layer\n",
    "    model.add(keras.layers.AveragePooling1D(pool_size=kernel_size, strides=stride,\n",
    "                                            name='AvgPool'))\n",
    "    # normalize input\n",
    "    model.add(keras.layers.BatchNormalization(axis=2, name='Norm_0'))\n",
    "    # flatten before the dense layers\n",
    "    model.add(keras.layers.Flatten(name='Flat'))\n",
    "    # for every layer\n",
    "    for i, layer_size in enumerate(layers):\n",
    "        # Add dense layer with activation_func\n",
    "        model.add(keras.layers.Dense(layer_size, activation=activation,\n",
    "                                     name=f'Dense_{i+1}'))\n",
    "        # Add batch normalization\n",
    "        if with_norm:\n",
    "            model.add(keras.layers.LayerNormalization(\n",
    "                axis=1, name=f'Norm_{i+1}'))\n",
    "        # Add dropout\n",
    "        if dropout > 0 and dropout < 1:\n",
    "            model.add(keras.layers.Dropout(dropout, name=f'Dropout_{i+1}'))\n",
    "    model.add(keras.layers.Dense(n_outputs, name=f'Output'))\n",
    "\n",
    "    # Now compile the model\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "phase_tuner = kt.Hyperband(phase_model_builder,\n",
    "                           objective='mse',\n",
    "                           max_epochs=40,\n",
    "                           factor=3,\n",
    "                           directory='keras_phase_hyperparam',\n",
    "                           project_name='otfb_lhc_ml')\n",
    "                           \n",
    "stop_early1 = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                            patience=5, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train the network\n",
    "\n",
    "phase_tuner.search(X_train, y_train[:, 0],\n",
    "                   validation_data=(X_test, y_test[:, 0]),\n",
    "                   epochs=20, callbacks=[stop_early1])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = phase_tuner.get_best_hyperparameters(num_trials=1)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below the definition of the gain prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# n_inputs = X_train.shape[1:]\n",
    "# n_outputs = 1\n",
    "\n",
    "# model2 = get_keras_nn(n_inputs, n_outputs, name='gain_regressor', activation='gelu',\n",
    "#                       layers=[420, 350], kernel_size=4, stride=4, trim_edges=120,\n",
    "#                       with_norm=True)\n",
    "# print(model2.summary())\n",
    "\n",
    "# model2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "#                loss=\"mse\")\n",
    "\n",
    "# stop_early2 = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "#                                             patience=5, restore_best_weights=True)\n",
    "# save_best2 = keras.callbacks.ModelCheckpoint(filepath='models/keras/regression/gain',\n",
    "#                                              monitor='val_loss', save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train the network\n",
    "# gain_history = model2.fit(X_train, y_train[:, 1],\n",
    "#                            validation_data=(X_test, y_test[:, 1]),\n",
    "#                            epochs=20, callbacks=[stop_early2, save_best2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the models\n",
    "# model1 = keras.models.load_model('models/keras/regression/phase_best')\n",
    "# model2 = keras.models.load_model('models/keras/regression/gain_best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def curve_fit_deluxe(func, freq, sample, trim_edges=0, kernel_size=1, stride=1, **kwargs):\n",
    "#     # center crop sample\n",
    "#     if trim_edges > 0:\n",
    "#         freq, sample = freq[trim_edges:-trim_edges], sample[trim_edges:-trim_edges]\n",
    "#     # prepare the shapes for avg_pooling\n",
    "#     freq = freq.reshape(1, -1, 1)\n",
    "#     sample = sample.reshape(1, -1, 1)\n",
    "#     # perform average pooling\n",
    "#     freq = avg_pool1d(pool_size=kernel_size, strides=stride)(freq).numpy().flatten()\n",
    "#     sample = avg_pool1d(pool_size=kernel_size, strides=stride)(sample).numpy().flatten()\n",
    "#     # pass to curve_fit\n",
    "#     return curve_fit(func, freq, sample, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get curve fit predictions\n",
    "# gen_tf = GenerateTF(fb_attn_index=3, with_noise=False)\n",
    "# freq = gen_tf.frequency.astype(np.float32)\n",
    "# y_optimizer = []\n",
    "# for sample in X_validate_orig[:, :, 2]:\n",
    "#     popt, _ = curve_fit_deluxe(gen_tf, freq, sample, trim_edges=130, kernel_size=4, stride=1,\n",
    "#                                bounds=([-20, 1e-4], [20, 1e-2]), method='trf')\n",
    "#     y_optimizer.append(popt)\n",
    "# y_optimizer = np.array(y_optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get model's predictions\n",
    "# y_nn_phase = model1.predict(X_validate).flatten()\n",
    "# y_nn_gain = model2.predict(X_validate).flatten()\n",
    "# y_nn = np.array([y_nn_phase, y_nn_gain]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert from category to value\n",
    "# y_nn_descaled = target_scaler.inverse_transform(y_nn)\n",
    "# y_nn_phase_descaled = y_nn_descaled[:, 0]\n",
    "# y_nn_gain_descaled = y_nn_descaled[:, 1]\n",
    "\n",
    "# phase_loss = model1.evaluate(X_validate, y_validate[:, 0])\n",
    "# gain_loss = model2.evaluate(X_validate, y_validate[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# r2_nn = r2_score(y_validate_orig, y_nn_descaled,\n",
    "#                    multioutput='raw_values')\n",
    "# mse_nn = mean_squared_error(y_validate_orig, y_nn_descaled,\n",
    "#                                multioutput='raw_values')\n",
    "\n",
    "# r2_opt = r2_score(y_validate_orig, y_optimizer,\n",
    "#                   multioutput='raw_values')\n",
    "# mse_opt = mean_squared_error(y_validate_orig, y_optimizer,\n",
    "#                               multioutput='raw_values')\n",
    "\n",
    "# print('R2\\tPhase\\tGain')\n",
    "# print('NeuralNet: ', r2_nn)\n",
    "# print('Optimizer:', r2_opt)\n",
    "\n",
    "# print('MSE\\tPhase\\tGain')\n",
    "# print('NeuralNet: ', mse_nn)\n",
    "# print('Optimizer:', mse_opt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(7, 6))\n",
    "\n",
    "# table = PrettyTable()\n",
    "# table.field_names = [\"idx\", \"param\", \"original\", \"NN\", \"Opt\"]\n",
    "\n",
    "# gen_tf = GenerateTF(fb_attn_index=3, with_noise=False)\n",
    "# freq = gen_tf.frequency.astype(np.float32)\n",
    "\n",
    "# for idx in np.random.choice(np.arange(0, len(X_validate)), size=3):\n",
    "#     try:\n",
    "#         popt, _ = curve_fit_deluxe(gen_tf, freq, X_validate_orig[idx, :, 2], trim_edges=130, kernel_size=4, stride=1,\n",
    "#                                    bounds=([-20, 1e-4], [20, 1e-2]), method='trf')\n",
    "#     except:\n",
    "#         print(f'Scipy curve fit failed for idx: {idx}')\n",
    "#         continue\n",
    "\n",
    "#     table.add_row([idx, 'phase', y_validate_orig[idx]\n",
    "#                   [0], y_nn_descaled[idx][0], popt[0]])\n",
    "#     table.add_row([idx, 'gain', y_validate_orig[idx][1],\n",
    "#                   y_nn_descaled[idx][1], popt[1]])\n",
    "\n",
    "#     p = plt.plot(\n",
    "#         freq, gen_tf(freq, *(y_validate_orig[idx])), label=f'real_{idx}', ls='-')\n",
    "#     plt.plot(freq, gen_tf(\n",
    "#         freq, *(y_nn_descaled[idx])), label=f'NN_{idx}', ls='--', color=p[0].get_color())\n",
    "#     plt.plot(freq, gen_tf(freq, *popt),\n",
    "#              label=f'opt_{idx}', ls=':', color=p[0].get_color())\n",
    "#     # plt.plot(x, gen_tf(x, *poptModel), label=f'opt+model_{idx}', ls='-.', color=p[0].get_color())\n",
    "# print(table)\n",
    "# plt.legend(ncol=3)\n",
    "# plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "79ab8fd01a8cec42884b8b2a5d7fb4751c5402d97e9e61d151ed5c6a6352873c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
