{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Example curve prediction script\n",
    "In this notebook we will try to predict the function coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from generate_TF import GenerateTF\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorchClassifiers import Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_pickle('./data/transfer-functions-82000.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "phi_encoder = preprocessing.LabelEncoder()\n",
    "phi_encoder.fit(df['phi'])\n",
    "print(phi_encoder.classes_)\n",
    "\n",
    "gain_encoder = preprocessing.LabelEncoder()\n",
    "gain_encoder.fit(df['g_oo'])\n",
    "print(gain_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "for index, row in df.sample(n=3).iterrows():\n",
    "    y = row['y']\n",
    "    x = row['x']\n",
    "    plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "values = np.zeros((len(df), len(df.loc[0, 'y'])), dtype=np.float32)\n",
    "# print(values.shape)\n",
    "index = 0\n",
    "for _, row in df.iterrows():\n",
    "    values[index, :] = row['y']\n",
    "    index += 1\n",
    "\n",
    "data_scaler = preprocessing.StandardScaler().fit(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize model, loss function and optimizer\n",
    "# This is for the first parameter: phi\n",
    "n_inputs = values.shape[1]\n",
    "# we will build one model per output target\n",
    "n_outputs = len(phi_encoder.classes_)\n",
    "model1 = Net(n_inputs, n_outputs, name='phase_classifier', activation_func=F.gelu,\n",
    "             hidden_1=500, hidden_2=200, hidden_3=0,\n",
    "             avg_pool=(6, 6), trim_edges=135, verbose=1,\n",
    "             with_batch_norm=True, save_best=True)\n",
    "print(model1)\n",
    "\n",
    "# specify loss function (regression)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize model, loss function and optimizer\n",
    "# This is for the second parameter: g_oo\n",
    "\n",
    "n_inputs = values.shape[1]\n",
    "# we will build one model per output target\n",
    "n_outputs = len(gain_encoder.classes_)\n",
    "\n",
    "model2 = Net(n_inputs, n_outputs, name='gain_classifier', activation_func=F.gelu,\n",
    "             hidden_1=420, hidden_2=350, hidden_3=0,\n",
    "             avg_pool=(4,4), trim_edges=120, save_best=True)\n",
    "print(model2)\n",
    "\n",
    "# specify loss function (regression)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load model with the highest accuracy\n",
    "# model1.load_state_dict(torch.load('models/model1-classifier-acc50.pt'))\n",
    "# model2.load_state_dict(torch.load('models/model2.pt'))\n",
    "\n",
    "model1.load(optimizer=optimizer1, filename='models/phase_classifier-acc62.pt')\n",
    "model2.load(optimizer=optimizer2, filename='models/gain_classifier-acc99.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from generate_TF import GenerateTF\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def curve_fit_deluxe(func, x, sample, trim_edges=0, kernel_size=1, stride=1, **kwargs):\n",
    "    # center crop sample\n",
    "    if trim_edges > 0:\n",
    "        x, sample = x[trim_edges:-trim_edges], sample[trim_edges:-trim_edges]\n",
    "    # convert to tensor for average pooling\n",
    "    x = torch.tensor(x).view(1, -1)\n",
    "    sample = torch.tensor(sample).view(1, -1)\n",
    "    # average pool sample\n",
    "    x = F.avg_pool1d(x, kernel_size=kernel_size, stride=stride).ravel().numpy()\n",
    "    sample = F.avg_pool1d(sample, kernel_size=kernel_size, stride=stride).ravel().numpy()\n",
    "    return curve_fit(func, x, sample, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This region is to use gradio and visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def classify(phase, gain):\n",
    "    phase, gain = float(phase), float(gain)\n",
    "    print(phase, gain)\n",
    "    # table = PrettyTable()\n",
    "    # table.field_names = [\"param\", \"original\", \"model\", \"opt\"]\n",
    "    table = []\n",
    "    gen_tf_noise = GenerateTF(fb_attn_index=3, with_noise=True)\n",
    "    x = gen_tf_noise.frequency\n",
    "\n",
    "    gen_tf_no_noise = GenerateTF(fb_attn_index=3, with_noise=False)\n",
    "\n",
    "    # I get one input with given phase, gain from X_validate or y_validate\n",
    "    y = gen_tf_noise(x, phase, gain)\n",
    "    y_scaled = torch.tensor(data_scaler.transform([y]), dtype=torch.float32)\n",
    "\n",
    "    phase_encoded = phi_encoder.transform([phase])\n",
    "    gain_encoded = gain_encoder.transform([gain])\n",
    "\n",
    "    # I make predictions with models + optimizer\n",
    "    with torch.no_grad():\n",
    "        model1.eval()\n",
    "        model2.eval()\n",
    "        pred_phase = model1(torch.atleast_2d(y_scaled))\n",
    "        pred_gain = model2(torch.atleast_2d(y_scaled))\n",
    "\n",
    "    # Extract top category\n",
    "    _, pred_phase = torch.exp(pred_phase).topk(1, dim=1)\n",
    "    _, pred_gain = torch.exp(pred_gain).topk(1, dim=1)\n",
    "\n",
    "    # Get original value\n",
    "    pred_phase = phi_encoder.inverse_transform(pred_phase.ravel().numpy())[0]\n",
    "    pred_gain = gain_encoder.inverse_transform(pred_gain.ravel().numpy())[0]\n",
    "\n",
    "    # Get optimizers results\n",
    "    (opt_phase, opt_gain), _ = curve_fit_deluxe(gen_tf_no_noise, x, y, trim_edges=130,\n",
    "                                                kernel_size=4, stride=1,\n",
    "                                                bounds=([-20, 0.001], [20, 0.005]), method='trf')\n",
    "\n",
    "    # I add them to the table\n",
    "    table.append(['phase', float(np.round(phase, 2)), float(np.round(pred_phase, 2)), float(np.round(opt_phase, 2))])\n",
    "    table.append(['gain', float(np.round(gain, 4)), float(np.round(pred_gain, 4)), float(np.round(opt_gain, 4))])\n",
    "\n",
    "    # I plot them\n",
    "    fig = plt.figure()\n",
    "    p = plt.plot(x, gen_tf_no_noise(x, phase, gain), label=f'True', ls='-', color='black')\n",
    "    plt.plot(x, gen_tf_noise(x, phase, gain), label=f'True, with Noise', ls='-', color='black', alpha=0.5)\n",
    "    plt.plot(x, gen_tf_no_noise(x, pred_phase, pred_gain), label=f'NeuralNet',\n",
    "             ls='--', color='tab:orange')\n",
    "    plt.plot(x, gen_tf_no_noise(x, opt_phase, opt_gain), label=f'Optimizer',\n",
    "             ls=':', color='tab:green')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend()\n",
    "    # print(table.get_string())\n",
    "    return fig, table\n",
    "\n",
    "fig, table = classify(-20, 0.005)\n",
    "fig.show()\n",
    "# print(table)\n",
    "\n",
    "# return: an array (with the predicted/ real values) + a figure with the ploted lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# print(gain_encoder.classes_.astype(str).tolist())\n",
    "# build the gradio interface\n",
    "interface = gr.Interface(fn=classify,\n",
    "                         inputs=[\n",
    "                             gr.Slider(label=f'Phase', minimum=-20., maximum=20., step=1.),\n",
    "                             gr.Dropdown(label='Gain', choices=gain_encoder.classes_.astype(str).tolist(),\n",
    "                                         type=\"value\"),\n",
    "                             # gr.Dropdown([\"KNN\", \"SoftMax\", \"KerasShallow\", \"KerasDeep\"], label='Choose Model'),\n",
    "                         ],\n",
    "                         outputs=[\n",
    "                             gr.Plot(label='Graphical Evaluation'),\n",
    "                             # gr.Textbox(lines=5),\n",
    "                             gr.DataFrame(label='Numerical Evaluation',\n",
    "                                          headers=['Param', 'True', 'NeuralNet', 'Optimizer'],\n",
    "                                          datatype=['str', 'number', 'number', 'number'],\n",
    "                                          row_count=2, col_count=(4, 'fixed'))\n",
    "                         ],\n",
    "                         interpretation=\"default\",\n",
    "                         )\n",
    "\n",
    "interface.launch(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "79ab8fd01a8cec42884b8b2a5d7fb4751c5402d97e9e61d151ed5c6a6352873c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
